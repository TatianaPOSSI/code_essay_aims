{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5fu9EDIulJTgt2RF7Susp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":18,"metadata":{"id":"My6zTt4mfVrP","executionInfo":{"status":"ok","timestamp":1715420770962,"user_tz":-60,"elapsed":1175,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}}},"outputs":[],"source":["#packges\n","import numpy as np\n","import pandas as pd\n","import yfinance as yf\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from scipy.optimize import minimize\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Function to get historical stock prices from Yahoo Finance\n","def get_stock_data(ticker, start_date, end_date):\n","    stock_data = yf.download(ticker, start=start_date, end=end_date)\n","    return stock_data['Adj Close']\n"],"metadata":{"id":"2Za3vy2lfjoq","executionInfo":{"status":"ok","timestamp":1715420771973,"user_tz":-60,"elapsed":25,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["#  tickers (27 compagnies) and dates\n","\n","tickers = ['AAPL', 'MSFT', 'GOOG', 'AMZN', 'BRK-A', 'NVDA', 'V', 'JPM', 'UNH',\n","           'JNJ', 'BAC', 'WMT', 'PG', 'HD', 'MA', 'XOM', 'PFE', 'DIS', 'CVX',\n","           'KO', 'AVGO', 'PEP', 'CSCO', 'WFC', 'COST', 'LLY', 'ADBE']\n","start_date = '2009-12-31'\n","end_date = '2021-12-31'"],"metadata":{"id":"qYTlfJ3zf8T5","executionInfo":{"status":"ok","timestamp":1715420771974,"user_tz":-60,"elapsed":24,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Policy gradient algorithm for portfolio optimization\n","class PolicyGradientPortfolioOptimization:\n","    def __init__(self, tickers, start_date, end_date, initial_cash=100000):\n","        self.tickers = tickers\n","        self.start_date = start_date\n","        self.end_date = end_date\n","        self.initial_cash = initial_cash\n","        self.num_stocks = len(tickers)\n","        self.stock_prices = self.get_stock_prices()\n","        self.portfolio = np.zeros(self.num_stocks)\n","        self.cash = initial_cash\n","        self.discount_factor = 0.95\n","        self.learning_rate = 0.01\n","        self.num_episodes = 1000\n","        self.policy = np.ones((self.num_stocks + 1, self.num_stocks + 1)) / (self.num_stocks + 1)\n","        self.svm_models = [SVR(kernel='rbf') for _ in range(self.num_stocks)]\n","        self.dt_models = [DecisionTreeRegressor() for _ in range(self.num_stocks)]\n","\n","    def get_stock_prices(self):\n","        stock_prices = []\n","        for ticker in self.tickers:\n","            stock_data = get_stock_data(ticker, self.start_date, self.end_date)\n","            stock_prices.append(stock_data)\n","        return np.array(stock_prices)\n","\n","    def select_action(self, state):\n","        probabilities = self.policy[state]\n","        probabilities /= np.sum(probabilities)  # Normalize probabilities\n","        return np.random.choice(range(self.num_stocks + 1), p=probabilities)\n","\n","    def update_policy(self, states, actions, rewards):\n","        for i in range(len(states)):\n","            state = states[i]\n","            action = actions[i]\n","            reward = rewards[i]\n","            state_int = int(state)\n","            self.policy[state_int, action] += self.learning_rate * reward\n","\n","    def step(self, action):\n","        if action == self.num_stocks:  # Hold cash\n","            return\n","        else:\n","            stock_price = self.stock_prices[action, -1]\n","            stock_quantity = self.cash / (self.num_stocks * stock_price)\n","            self.portfolio[action] += stock_quantity\n","            self.cash -= stock_quantity * stock_price\n","\n","    def train(self):\n","        for episode in range(self.num_episodes):\n","            states = []\n","            actions = []\n","            rewards = []\n","            state = int(self.cash / (self.initial_cash / self.num_stocks))\n","            for _ in range(100):  # 100 steps per episode\n","                action = self.select_action(state)\n","                actions.append(action)\n","                self.step(action)\n","                next_state = int(self.cash / (self.initial_cash / self.num_stocks))\n","                reward = np.sum(self.portfolio * self.stock_prices[:, -1])\n","                states.append(state)\n","                rewards.append(reward)\n","                state = next_state\n","            self.update_policy(states, actions, rewards)\n","            if episode % 100 == 0:\n","                print(f\"Episode {episode}, Portfolio Value: {np.sum(self.portfolio * self.stock_prices[:, -1])}\")\n","    def calculate_Policy_gradient_weights(self):\n","        returns = np.diff(np.log(self.stock_prices), axis=1)\n","        expected_returns = np.mean(returns, axis=1)\n","        cov_matrix = np.cov(returns)\n","\n","        def objective(weights):\n","            return -np.dot(expected_returns, weights)  # Maximize expected return\n","\n","        def constraint(weights):\n","            return np.sum(weights) - 1  # Sum of weights equals 1\n","\n","        initial_weights = np.ones(self.num_stocks) / self.num_stocks  # Equal weights initially\n","        bounds = [(0, 1) for _ in range(self.num_stocks)]\n","        constraints = [{'type': 'eq', 'fun': constraint}]\n","\n","        result = minimize(objective, initial_weights, bounds=bounds, constraints=constraints)\n","        return result.x\n","\n","\n","    def get_portfolio_weights(self):\n","        if np.sum(self.cash) == 0:\n","            cash_weight = 0\n","        else:\n","            cash_weight = self.cash / np.sum(self.cash)\n","        stock_weights = self.portfolio / np.sum(self.portfolio)\n","        return np.concatenate(([cash_weight], stock_weights))\n","\n","\n"],"metadata":{"id":"Dp52CF41RPo9","executionInfo":{"status":"ok","timestamp":1715420796809,"user_tz":-60,"elapsed":892,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Q-learning algorithm for portfolio optimization\n","class QLearningPortfolioOptimization(PolicyGradientPortfolioOptimization):\n","    def __init__(self, tickers, start_date, end_date, initial_cash=100000):\n","        super().__init__(tickers, start_date, end_date, initial_cash)\n","        self.q_table = np.zeros((self.num_stocks + 1, self.num_stocks + 1))  # Q-table initialization\n","        self.epsilon = 0.1  # Epsilon for epsilon-greedy exploration\n","\n","    def select_action(self, state):\n","        if np.random.rand() < self.epsilon:\n","            return np.random.choice(range(self.num_stocks + 1))  # Random action\n","        else:\n","            return np.argmax(self.q_table[state])\n","\n","    def update_q_table(self, state, action, reward, next_state):\n","        max_next_q = np.max(self.q_table[next_state])\n","        self.q_table[state, action] += self.learning_rate * (reward + self.discount_factor * max_next_q - self.q_table[state, action])\n"],"metadata":{"id":"AtTPMQuLOJqn","executionInfo":{"status":"ok","timestamp":1715420798730,"user_tz":-60,"elapsed":25,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["\n","# Policy Gradient\n","policy_gradient = PolicyGradientPortfolioOptimization(tickers, start_date, end_date)\n","policy_gradient.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RONvw9R1gCiI","executionInfo":{"status":"ok","timestamp":1715420805413,"user_tz":-60,"elapsed":6706,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}},"outputId":"3b220466-b58b-498f-a7fb-dbec241f6392"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["Episode 0, Portfolio Value: 97524.06514555847\n","Episode 100, Portfolio Value: 100000.00000000003\n","Episode 200, Portfolio Value: 100000.00000000003\n","Episode 300, Portfolio Value: 100000.00000000003\n","Episode 400, Portfolio Value: 100000.00000000003\n","Episode 500, Portfolio Value: 100000.00000000003\n","Episode 600, Portfolio Value: 100000.00000000003\n","Episode 700, Portfolio Value: 100000.00000000003\n","Episode 800, Portfolio Value: 100000.00000000003\n","Episode 900, Portfolio Value: 100000.00000000003\n"]}]},{"cell_type":"code","source":["# Q-learning\n","q_learning = QLearningPortfolioOptimization(tickers, start_date, end_date)\n","q_learning.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMfxoMMEOiXg","executionInfo":{"status":"ok","timestamp":1715420809459,"user_tz":-60,"elapsed":4060,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}},"outputId":"2879db22-f764-4b82-e78f-b84a705acf11"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n"]},{"output_type":"stream","name":"stdout","text":["Episode 0, Portfolio Value: 97704.07138326137\n","Episode 100, Portfolio Value: 99999.99999999972\n","Episode 200, Portfolio Value: 99999.99999999972\n","Episode 300, Portfolio Value: 99999.99999999972\n","Episode 400, Portfolio Value: 99999.99999999972\n","Episode 500, Portfolio Value: 99999.99999999972\n","Episode 600, Portfolio Value: 99999.99999999972\n","Episode 700, Portfolio Value: 99999.99999999972\n","Episode 800, Portfolio Value: 99999.99999999972\n","Episode 900, Portfolio Value: 99999.99999999972\n"]}]},{"cell_type":"code","source":["portfolio_weights_q = q_learning.get_portfolio_weights()"],"metadata":{"id":"BBJi_dIdOOnr","executionInfo":{"status":"ok","timestamp":1715420809460,"user_tz":-60,"elapsed":14,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["#Q_learning weights\n","Q_weights=pd.DataFrame(portfolio_weights_q[1:],index=tickers)\n","Q_weights.to_csv('Q_learning_w.csv')"],"metadata":{"id":"NoXBSegEO43f","executionInfo":{"status":"ok","timestamp":1715420809461,"user_tz":-60,"elapsed":13,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Calculate Policy_gradient weights\n","pg_weights = policy_gradient.calculate_Policy_gradient_weights()\n","weights=pd.DataFrame(pg_weights,index=tickers)\n","weights.to_csv('Policy_gradient_w.csv')\n"],"metadata":{"id":"fpMS7Sv-QbL5","executionInfo":{"status":"ok","timestamp":1715420811395,"user_tz":-60,"elapsed":1945,"user":{"displayName":"Rayda Tatiana POSSI TAHABO - 2023 intake","userId":"10749519103995593295"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Rfr1BC_ZFFdE"},"execution_count":null,"outputs":[]}]}